{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9fjV2dALrvb"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxmcgnZeNAB-"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "pipe = pipeline('text-classification', model=model_name,\n",
    "                 tokenizer=model_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Co7tPg9LNUcr"
   },
   "outputs": [],
   "source": [
    "pipe(\"Verpackung gut, Produkt absolut unbrauchbar - geht zurück\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3uqcvec7Nh-O"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sFRTI5pOLEt"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "# das Modell muss zum Tokenizer passen!\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False # wir benötigen keine Embeddings\n",
    ")\n",
    "# hier evtl. model.cpu() einsetzen\n",
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ObcHQwXOdEi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "at = pd.DataFrame([{ \"text\": \"Heute ist ein furchtbarer Tag\"}, {\"text\": \"Heute ist ein wunderschöner Tag\"}])\n",
    "at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obuQws4oON8S"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "scores = []\n",
    "for i in tqdm(range(len(at)//100 + 1)):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for t in at[i*100:(i+1)*100][\"text\"].map(str).values:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            t,\n",
    "                            add_special_tokens = True,    # '[CLS]' und '[SEP]'\n",
    "                            max_length = 64,\n",
    "                            truncation = True,\n",
    "                            padding='max_length',\n",
    "                            return_attention_mask = True,  # Attention-Masks erzeugen\n",
    "                            return_tensors = 'pt',         # pytorch-Tensoren als Ergebnis\n",
    "                       )\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "        \n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)        \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        res = model(input_ids.to(device), attention_mask=attention_masks.to(device))\n",
    "        for r in res[0].cpu().detach().numpy():\n",
    "            scores.append(list(softmax(r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PewSh4e_OtZ6"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(scores, columns=range(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfsqZ0VOO2KT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "08-Sentiments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
