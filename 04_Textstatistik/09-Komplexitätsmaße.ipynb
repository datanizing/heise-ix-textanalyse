{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Komplexitätsmaße"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den vorigen Lektionen haben wir schon mit Tokens pro Satz hantiert. Je länger ein Satz ist, desto schwerer ist er verständlich.\n",
    "\n",
    "Allerdings gibt es noch weit mehr Größen, die du dafür ermitteln kannst. Die werden wir uns jetzt genauer ansehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einladen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie gewohnt lädst du zunächst die linguistisch analysierten Daten aus der Datenbank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textacy\n",
    "!python -m spacy download de_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    os.system(\"test -f heise-articles-2020.db || wget  https://datanizing.com/heiseacademy/nlp-course/blob/main/99_Common/heise-articles-2020.db.gz && gunzip heise-articles-2020.db.gz\")\n",
    "    newsticker_db = 'heise-articles-2020.db'\n",
    "else:\n",
    "    newsticker_db = '../99_Common/heise-articles-2020.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 \n",
    "import pandas as pd\n",
    "\n",
    "sql = sqlite3.connect(newsticker_db)\n",
    "df = pd.read_sql(\"SELECT * FROM nlp_articles \\\n",
    "                   WHERE datePublished<'2021-01-01' \\\n",
    "                   ORDER BY datePublished\", sql, index_col=\"id\", parse_dates=[\"datePublished\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nochmal Tokens pro Satz berechnen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Verleich berechnest du nochmal die Anzahl der Tokens pro Satz und lässt dir das Ergebnis als Histogramm anzeigen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"token_per_sentence\"] = df[\"no_tokens\"] / df[\"no_sentences\"]\n",
    "df[[\"token_per_sentence\"]].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie du sehen kannst, ist die Bandbreite ganz erheblich. Die meisten Artikel liegen zwischen 8 Tokens pro Satz und 20 Tokens pro Satz. Das wollen wir uns nun genauer anschauen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Komplexitätsmaße berechnen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst brauchst du wieder `spacy` und das geeignete Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"de_core_news_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Über `textacy` kannst du nun die Komplexitätsmaße berechnen. Der Durchlauf braucht ungefähr 10 Minuten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy.text_stats\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "df[\"fulltext\"] = df[\"title\"] + \"\\n\" + df[\"header\"] + \"\\n\" + df[\"text\"]\n",
    "for i, r in tqdm(df.iterrows(), total=len(df)):\n",
    "    tdoc = textacy.make_spacy_doc(r[\"fulltext\"], lang=\"de_core_news_lg\")\n",
    "    ts = textacy.text_stats.TextStats(tdoc)\n",
    "    df.at[i, \"entropy\"] = ts.entropy\n",
    "    df.at[i, \"coleman_liau_index\"] = ts.coleman_liau_index\n",
    "    df.at[i, \"gunning_fog_index\"] = ts.gunning_fog_index\n",
    "    df.at[i, \"flesch_kincaid_grade_level\"] = ts.flesch_kincaid_grade_level\n",
    "    df.at[i, \"smog_index\"] = ts.smog_index\n",
    "    df.at[i, \"wiener_sachtextformel\"] = ts.wiener_sachtextformel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genauer Informationen zu den Metriken findest du unter https://textacy.readthedocs.io/en/0.10.1/api_reference/misc.html#textacy.text_stats.api.TextStats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Entropie des Textes, d.h. umso höher, je mehr Durcheinander in den Wörtern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"entropy\"]].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coleman Liau Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesbarkeitsindex, der die Jahre der Schulbildung zählt, die für ein Verständnis notwendig sind. Ähnlich zu `flesch_kincaid_grade_level()` und `smog_index()`, allerdings werden Zeichen pro Wort statt Silben verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"coleman_liau_index\"]].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smog Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesbarkeitstest aus medizinischer Literatur und Healthcare. Auch hier werden die Jahre an Schulbildung abgeschätzt, die zum Verständnis notwendig sind. Ähnlich zu `flesch_kincaid_grade_level()` und auch als Ersatz für `gunning_fog_index()` gedacht.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"smog_index\"]].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flesch Kincaid Grade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einer der beliebtesten Lesbarkeitsindizes, weil er ganz generell und sprachunabhänig verwendet werden kann. Schätzt ebenfalls die Anzahl der Schuljahre zum Verständnis ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"flesch_kincaid_grade_level\"]].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wiener Sachtextformel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Index ist spezifisch für deutsche Sprache konstruiert und wird in deutschsprachiger Literatur überwiegend verwendet. Auch hier wird wieder die Anzahl der zum Verständnis notwendigen Schuljahre abgeschätzt-."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"wiener_sachtextformel\"]].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schreibstil von Autoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist interessant, die Komplexität der Texte unterschiedliche Autoren zu vergleichen. Im ersten Schritt bestimmst du dazu die Top-20-Autoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_authors = df.groupby(\"author\").agg({\"url\": \"count\"}).sort_values(\"url\").tail(20).index.values\n",
    "top_author_articles = df[df[\"author\"].isin(top_authors)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie schon in der letzten Lektion gezeigt, berechnen wir zunächst den Median der Wiener Sachtextformel-Werte und ordnen die Labels entsprechend. Statt eines Boxplots verwenden wir einen sog. *Violin-Plot*, der noch etwas mehr Information beinhaltet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 10))\n",
    "labels = top_author_articles.groupby(\"author\").agg({\"wiener_sachtextformel\": \"median\"}).sort_values(\"wiener_sachtextformel\").index.values\n",
    "sns.violinplot(y=\"author\", x=\"wiener_sachtextformel\", data=top_author_articles, order=labels, palette=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Auswertung kannst du erkennen, dass *Daniel AJ Sokolov* zwar relativ gut lesbar schreibt, aber einige Ausreißer hat, die schwierig zu lesen sind. Gleiches gilt für *Alexander Neumann*. *Olivia von Westernhagen* deckt ein großes Spektrum ab ebenso wie *Bernd Mewes*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du kannst dir noch die am schwierigsten zu lesenden Artikel ausgeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df.sort_values(\"wiener_sachtextformel\").tail(10)[[\"author\", \"title\", \"url\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du kannst nun selbst die Artikel aufrufen und überlegen, ob die wirklich besonders schwer lesbar sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesbarkeit enthält viel Heuristik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Formeln zur Berechnung der Lesbarkeitswerte sind relativ kompliziert und sehr heuristisch. Ob der Index im Einzelfall wirklich die Komplexität abbildet, kannst du selbst überprüfen - es wird nicht immer stimmen. Über die Statistik und die große Menge an Daten gleicht sich das im Allgemeinen wieder aus. Du solltest nur im Hinterkopf behalten, dass es sich um *Phänomenologie* handelt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
